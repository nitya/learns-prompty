{"config":{"lang":["en"],"separator":"[\\s\\u200b\\-_,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":"<p>Learning Resources For Developers</p> <ul> <li>Read the documentation</li> <li>Watch the video</li> <li>Explore the repo</li> </ul>"},{"location":"#what-is-prompty","title":"What is Prompty?","text":"<p>Prompty is a new asset class and format for LLM prompts that aims to provide observability, understandability, and portability for developers. It consists of three main components: </p> <ul> <li>the Prompty Specification - a format that describes the asset.</li> <li>the Prompty Tools - developer workflows to create &amp; manage assets.</li> <li>the Prompty Runtime - convert asset to code, for testing &amp; usage.</li> </ul> <p></p>"},{"location":"#how-do-we-use-prompty","title":"How do we use Prompty?","text":"<p>Prompty is ideal for rapid prototyping and iteration of a new generative AI application, using rich developer tooling and a local development runtime.</p> <ul> <li>Start by creating &amp; testing a simple prompt in VS Code</li> <li>Develop by iterating config &amp; content, use tracing to debug</li> <li>Evaluate prompts with AI assistance, saved locally or to cloud</li> </ul> <p></p>"},{"location":"#where-do-we-use-prompty","title":"Where do we use Prompty?","text":"<p>There are many tools &amp; frameworks for building generative AI solutions today. So where does Prompty fit? Think of it as a micro-orchestrator for a single LLM invocation where you can:</p> <ol> <li>configure a specific model for your needs</li> <li>create the template content (system, user, context, instructions)</li> <li>shape the data used to \"render\" template for a real invocation</li> </ol> <p>The Prompty tools and runtime can convert the asset into code that can then be used with richer frameworks (like Semantic Kernel, LangChain, Prompt flow and more) to orchestrate more complex workflows for your application.</p> <p></p>"},{"location":"#prompty-for-developers","title":"Prompty For Developers","text":""},{"location":"#1-deep-dive-msbuild-session","title":"1. Deep Dive: MSBuild Session","text":"<p>Watch this replay from the Microsoft Build 2024 conference to learn how Prompty works, and how it can streamline your AI development journey from prompt to production. </p> <p>You can find a transcript of the session here. Save the file to your local device, open it in VS Code - then try using Copilot Chat to get a summary of the main points:</p> <p>This is the summarization prompt I used</p> <p>Summarize the transcript and generate a blog in Markdown format with the following components:</p> <p>Divide the summary into 6 topics with each topic described in a Markdown section The section should have a descriptive title followed by a short paragraph describing the topic, followed by a list of 4 bullet points that summarize what you learned in that section. Start the Markdown document with a brief description of the whole document and 4 bullet items about what the entire summary covers</p> This is the lightly-edited output of that prompt for reference <p>This document provides a summary of the BRK114 session held at Microsoft Build 2024. The session, led by Seth Juarez and Leah Bar On Simmons, covers various aspects of AI development using Prompty and AI Studio. Below are the key topics discussed:</p> <ul> <li>Overview of the Session</li> <li>Introduction to Prompty and AI Studio</li> <li>Getting Started with LLMs</li> <li>Prompty Specification</li> <li>Developing an App with Prompty</li> <li>Seth Juarez's Perspective on LLMs</li> </ul>"},{"location":"#11-session-overview","title":"1.1 Session Overview","text":"<p>The session, BRK114, is part of the Microsoft Build 2024 event and is presented by Seth Juarez and Leah Bar On Simmons. It focuses on practical end-to-end AI development using Prompty and AI Studio.</p> <ul> <li>Speakers: Seth Juarez, Leah Bar On Simmons</li> <li>Event: Microsoft Build 2024</li> <li>Session Focus: Practical AI development</li> <li>Audience Interaction: Encouraged feedback and questions</li> </ul>"},{"location":"#12-prompty-and-ai-studio","title":"1.2 Prompty and AI Studio","text":"<p>Seth Juarez introduces Prompty and AI Studio, highlighting their importance in AI development. He emphasizes the practical applications and the fun elements like logos, stickers, and merchandise.</p> <ul> <li>Tools Introduced: Prompty, AI Studio</li> <li>Session Tone: Interactive and engaging</li> <li>Merchandise: Stickers, T-shirts, hats</li> <li>Audience Engagement: Encouraged to ask questions</li> </ul>"},{"location":"#13-getting-started","title":"1.3 Getting Started","text":"<p>The session covers the basics of getting started with Large Language Models (LLMs) using Prompty in Visual Studio Code. Seth Juarez explains the initial steps and the importance of understanding the Prompty specification.</p> <ul> <li>Focus: Getting started with LLMs</li> <li>Tool: Visual Studio Code</li> <li>Specification: Prompty spec</li> <li>Initial Steps: Explained by Seth Juarez</li> </ul>"},{"location":"#14-prompty-specification","title":"1.4 Prompty Specification","text":"<p>Seth Juarez delves into the Prompty specification, explaining its significance and how it guides the development process. He emphasizes the structured approach provided by the specification.</p> <ul> <li>Specification: Prompty spec</li> <li>Importance: Guides development</li> <li>Structure: Provides a structured approach</li> <li>Explanation: Detailed by Seth Juarez</li> </ul>"},{"location":"#15-develop-ai-apps","title":"1.5 Develop AI Apps","text":"<p>The session includes a segment on developing an application using Prompty. Seth Juarez walks through the process, highlighting key aspects and best practices.</p> <ul> <li>Focus: App development with Prompty</li> <li>Process: Walkthrough by Seth Juarez</li> <li>Key Aspects: Highlighted during the session</li> <li>Best Practices: Discussed</li> </ul>"},{"location":"#16-seth-llm-perspective","title":"1.6 Seth LLM Perspective","text":"<p>Seth Juarez shares his unique perspective on Large Language Models, likening them to giant language calculators. He uses relatable examples to explain his viewpoint.</p> <ul> <li>Perspective: LLMs as language calculators</li> <li>Examples: Relatable and engaging</li> <li>Explanation Style: Unique and insightful</li> <li>Audience Engagement: Encouraged to follow along</li> </ul> <p>This summary captures the essence of the BRK114 session, providing a structured overview of the key topics discussed by Seth Juarez and Leah Bar On Simmons at Microsoft Build 2024.</p>"},{"location":"#2-hands-on-samples","title":"2. Hands-On Samples","text":""},{"location":"#21-contoso-chat-rag","title":"2.1 Contoso Chat (RAG)","text":"<p>Learn how to use Prompty to rapidly prototype a RAG-based retail copilot, from prompt engineering to evaluation and deployment, using the Contoso Chat sample. Click the image below to visit an interactive workshop guide.</p> <p></p>"},{"location":"#22-creative-writer-agentic","title":"2.2. Creative Writer (Agentic)","text":"<p>Learn how to use Prompty to build a rapid prototype for a multi-agent AI solution, integrating search and content creation, using the Contoso Creative Writer sample. Visit the repo for a link to an interactive workshop guide.</p> <p></p>"},{"location":"#23-ai-templates-azd","title":"2.3. AI Templates (AZD)","text":"<p>Want to explore more Azure AI application samples built with prompty? Check out the 2024 AI Templates collection released at Microsoft Build 2024 for early samples using diverse programming languages, frameworks, and deployment targets.</p> <p></p>"},{"location":"blog/","title":"About","text":"<p>Prompty Blog</p> <p>This blog complements the Prompty documentation with more personalized and time-specific content for learning and using Prompty. Check back for blog posts soon.</p> <p></p>"},{"location":"concepts/","title":"Table Of Contents","text":"<p>Learning objectives for this section</p> <ul> <li>Understand Prompty Specification</li> <li>Understand Prompty Tooling</li> <li>Understand Prompty Runtime</li> <li>See Prompty Asset In Action</li> </ul>"},{"location":"concepts/00/","title":"1. Prompty Specification","text":""},{"location":"concepts/01/","title":"2. Prompty Tooling","text":""},{"location":"concepts/02/","title":"3. Prompty Runtime","text":""},{"location":"concepts/03/","title":"4. Prompty Asset","text":""},{"location":"tutorials/","title":"Table Of Contents","text":"<p>Learning Objectives for this section</p> <p>Learn to use the Prompty tools &amp; runtime for prompt engineering and rapid protottyping of generative AI applications - with hands-on exercises using a code-first approach. Example exercises may include:</p> <ul> <li>Learn to create, configure, and run, a simple Prompty asset in VS Code.</li> <li>Learn to create, configure, and run, a Prompty asset from code.</li> <li>Use Prompty assets with OpenAI models.</li> <li>Use Prompty assets with Azure OpenAI models.</li> <li>Use Prompty assets with GitHub Marketplace models.</li> <li>Use Prompty assets with Azure AI Catalog models (managed).</li> <li>Use Prompty assets with Azure AI Catalog models (serverless).</li> <li>Use Prompty assets with Hugging Face Hub models (open-source).</li> <li>Build a RAG-based AI application with Prompty assets.</li> <li>Orchestrate a multi-agent workflow with Prompty assets.</li> <li>Evaluate your AI application using Prompty assets.</li> </ul>"}]}